{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from vahun.corpus import TSV_Corpus as Corpus\n",
    "import numpy as np\n",
    "from vahun.tools import Timer\n",
    "from vahun.tools import explog\n",
    "#from vahun.autoencoder import Autoencoder_ffnn\n",
    "from vahun.tools import show_performance\n",
    "from vahun.genetic import Settings\n",
    "from vahun.tools import get_reconstruction\n",
    "\n",
    "from vahun.Autoencoder_FFNN import Autoencoder_FFNN\n",
    "from vahun.Autoencoder_Variational import Autoencoder_Variational\n",
    "timer=Timer()\n",
    "\n",
    "\n",
    "\n",
    "corpus_path='/mnt/store/velkey/mnsz2/brain_split.200k.maxlen20'\n",
    "encode=100\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "Xcorpus=Corpus(corpus_path=corpus_path,col=0,size=0)\n",
    "Ycorpus=Corpus(corpus_path=corpus_path,col=1,size=0)\n",
    "\n",
    "logger=explog(encoder_type=\"demo_autoencoder_splitbrain_\"+str(encode),\n",
    "              encoding_dim=encode,\n",
    "              feature_len=20,\n",
    "              lang=corpus_path,\n",
    "              unique_words=len(set(Xcorpus.wordlist)),\n",
    "              name=\"demo_autoencoder_top_splitbrain_\"+str(encode),\n",
    "              population_size=0,\n",
    "              words=len(Xcorpus.wordlist))\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "encoder=Autoencoder_FFNN(\n",
    "                 logger=logger,tf_session=sess,\n",
    "                 inputdim=len(Xcorpus.abc)*20,\n",
    "                 layerlist=[encode,len(Xcorpus.abc)*20],\n",
    "                 encode_index=1,corpus=Xcorpus,\n",
    "                 optimizer =tf.train.AdamOptimizer(learning_rate = 0.001),\n",
    "                 nonlinear=tf.sigmoid,disp_step=100,\n",
    "                 charnum=len(Xcorpus.abc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memoryerror during train reconstruction,using only the half data!\n"
     ]
    }
   ],
   "source": [
    "encoder.train(Xcorpus.x_train,Xcorpus.x_valid,Xcorpus.x_test,\n",
    "              512,30,\n",
    "              Ycorpus.x_train,Ycorpus.x_valid,Ycorpus.x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "result=encoder.get_reconstruction_splitbrain(Xcorpus.x_test,Xcorpus,Ycorpus.x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('/mnt/store/velkey/splitbrain_200_encoding', \"a\") as myfile:\n",
    "    for it in result:\n",
    "        string=\"\"\n",
    "        for i in it:\n",
    "            string+=str(i)\n",
    "            string+='\\t'\n",
    "        string+='\\n'\n",
    "        myfile.write(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           túlhaladt \t            talhatatt\n",
      "           túlhaladt \t            súlhaledk\n",
      "        újdonságának \t         úldantásánal\n",
      "        újdonságának \t         ejeosszgának\n",
      "               akkus \t                aikas\n",
      "               akkus \t                okkuk\n",
      "          tokozásban \t           takszásbal\n",
      "          tokozásban \t           korolásban\n",
      "          kezdhettem \t           kszehetnek\n",
      "          kezdhettem \t           keldtettem\n",
      "            vásárnak \t             vasornak\n",
      "            vásárnak \t             kálásnak\n",
      "       járnak-kelnek \t        jereal-teknek\n",
      "       járnak-kelnek \t        kálnakekelnek\n",
      "            örvénybe \t             ölveneba\n",
      "            örvénybe \t             erményee\n",
      "           megyéknél \t            megyésnel\n",
      "           megyéknél \t            menyektét\n",
      "               chili \t                csini\n",
      "               chili \t                lheló\n",
      "               bújna \t                bajra\n",
      "               bújna \t                kúlni\n",
      "           kiújulása \t            kaútulása\n",
      "           kiújulása \t            kirjelást\n",
      "          foglyaként \t           fegnyekéni\n",
      "          foglyaként \t           kolltatést\n",
      "  munkanélküliségben \t   menkalélkelesegbel\n",
      "  munkanélküliségben \t   _uekeneleülisésben\n",
      "       hathatósabban \t        hetzalósatban\n",
      "       hathatósabban \t        kalhatasobban\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    print(result[i][3],'\\t',result[i][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 980 into shape (10,49)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-4a8b578a7f05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eh\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"kecske\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"kutya\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"aytuk\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"macska\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"árvíztűrő\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"fúró\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"kacsa\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"és\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXcorpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprinter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputfsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/velkey/vahun/vahun/tools.py\u001b[0m in \u001b[0;36mshow_performance\u001b[0;34m(encoder, data, corp, length, plot, printer, inputdepth, inputfsize, encodim)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0mcharacc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0mxa\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefeaturize_data_charlevel_onehot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputdepth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputfsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0mxb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefeaturize_data_charlevel_onehot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputdepth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputfsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mlevenshteins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLevenshtein\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxa\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 980 into shape (10,49)"
     ]
    }
   ],
   "source": [
    "std=show_performance(encoder,[\"eh\",\"kecske\",\"kutya\",\"aytuk\",\"macska\",\"árvíztűrő\",\"fúró\",\"kacsa\",\"a\",\"és\"],Xcorpus,printer=True,inputfsize=len(Xcorpus.abc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def decode_critical(lista,enc=180):\n",
    "    for POS in lista:\n",
    "        encoded=np.ones(enc)*-10\n",
    "        encoded[POS]=10\n",
    "        a=encoder.decode([encoded])[0].reshape([10,len(corpus.abc)])\n",
    "        b=corp.defeaturize_data_charlevel_onehot([a])\n",
    "        print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import heapq\n",
    "topstd=heapq.nlargest(6, range(len(stds)), stds.__getitem__)\n",
    "big_stuff=[]\n",
    "for i in range(50):\n",
    "    big_stuff.append([])\n",
    "    for topind in topstd:\n",
    "        a=encoder.encode([corpus.x_test[i]])\n",
    "        a[0][topind]=2\n",
    "        b=encoder.decode([a[0]])[0].reshape([10,len(corpus.abc)])\n",
    "        c=corpus.defeaturize_data_charlevel_onehot([b])\n",
    "        big_stuff[i].append(c)\n",
    "for row in big_stuff:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
