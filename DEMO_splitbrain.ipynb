{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from vahun.corpus import TSV_Corpus as Corpus\n",
    "import numpy as np\n",
    "from vahun.tools import Timer\n",
    "from vahun.tools import explog\n",
    "#from vahun.autoencoder import Autoencoder_ffnn\n",
    "from vahun.tools import show_performance\n",
    "from vahun.genetic import Settings\n",
    "from vahun.tools import get_reconstruction\n",
    "\n",
    "from vahun.Autoencoder_FFNN import Autoencoder_FFNN\n",
    "from vahun.Autoencoder_Variational import Autoencoder_Variational\n",
    "timer=Timer()\n",
    "\n",
    "\n",
    "\n",
    "corpus_path='/mnt/store/velkey/mnsz2/brain_split.200k.maxlen20'\n",
    "encode=400\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "Xcorpus=Corpus(corpus_path=corpus_path,col=0,size=0)\n",
    "\n",
    "Ycorpus=Corpus(corpus_path=corpus_path,col=1,size=0)\n",
    "\n",
    "logger=explog(encoder_type=\"demo_autoencoder_splitbrain\"+str(encode),\n",
    "              encoding_dim=encode,\n",
    "              feature_len=20,\n",
    "              lang=corpus_path,\n",
    "              unique_words=len(set(Xcorpus.wordlist)),\n",
    "              name=\"demo_autoencoder_top_splitbrain\"+str(encode),\n",
    "              population_size=0,\n",
    "              words=len(Xcorpus.wordlist))\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "encoder=Autoencoder_FFNN(\n",
    "                 logger=logger,tf_session=sess,\n",
    "                 inputdim=len(Xcorpus.abc)*20,\n",
    "                 layerlist=[encode,len(Xcorpus.abc)*20],\n",
    "                 encode_index=1,corpus=Xcorpus,\n",
    "                 optimizer =tf.train.AdamOptimizer(learning_rate = 0.001),\n",
    "                 nonlinear=tf.sigmoid,disp_step=100,\n",
    "                 charnum=len(Xcorpus.abc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memoryerror during train reconstruction,using only the half data!\n"
     ]
    }
   ],
   "source": [
    "encoder.train(Xcorpus.x_train,Xcorpus.x_valid,Xcorpus.x_test,\n",
    "              512,30,\n",
    "              Ycorpus.x_train,Ycorpus.x_valid,Ycorpus.x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['           t_l_a_a_t', '           _ú_h_l_d_', '           _a_h_t_t_', '           túlhaladt', '           talhatatt', 3]\n",
      "['           _ú_h_l_d_', '           t_l_a_a_t', '           s_l_a_a_ó', '           túlhaladt', '           súlhaladó', 2]\n",
      "['        ú_d_n_á_á_a_', '        _j_o_s_g_n_k', '        _l_o_t_s_b_n', '        újdonságának', '        úldontásában', 5]\n",
      "['        _j_o_s_g_n_k', '        ú_d_n_á_á_a_', '        a_k_s_á_á_a_', '        újdonságának', '        ajkosságának', 3]\n",
      "['               a_k_s', '               _k_u_', '               _i_o_', '               akkus', '               aikos', 2]\n",
      "['               _k_u_', '               a_k_s', '               o_j_k', '               akkus', '               okjuk', 3]\n",
      "['          t_k_z_s_a_', '          _o_o_á_b_n', '          _a_o_á_s_l', '          tokozásban', '          takozással', 3]\n",
      "['          _o_o_á_b_n', '          t_k_z_s_a_', '          k_r_l_s_a_', '          tokozásban', '          korolásban', 3]\n",
      "['          k_z_h_t_e_', '          _e_d_e_t_m', '          _s_e_e_t_k', '          kezdhettem', '          kszehettek', 3]\n",
      "['          _e_d_e_t_m', '          k_z_h_t_e_', '          m_n_t_t_e_', '          kezdhettem', '          mendtettem', 3]\n",
      "['            v_s_r_a_', '            _á_á_n_k', '            _a_á_b_k', '            vásárnak', '            vasárbak', 2]\n",
      "['            _á_á_n_k', '            v_s_r_a_', '            t_r_s_a_', '            vásárnak', '            tárásnak', 3]\n",
      "['       j_r_a_-_e_n_k', '       _á_n_k_k_l_e_', '       _e_e_t_m_k_e_', '       járnak-kelnek', '       jereat-meknek', 5]\n",
      "['       _á_n_k_k_l_e_', '       j_r_a_-_e_n_k', '       v_l_a_e_e_t_k', '       járnak-kelnek', '       válnakekeltek', 4]\n",
      "['            ö_v_n_b_', '            _r_é_y_e', '            _l_e_e_e', '            örvénybe', '            ölvenebe', 3]\n",
      "['            _r_é_y_e', '            ö_v_n_b_', '            e_m_n_r_', '            örvénybe', '            erményre', 3]\n",
      "['           m_g_é_n_l', '           _e_y_k_é_', '           _e_y_s_e_', '           megyéknél', '           megyésnel', 2]\n",
      "['           _e_y_k_é_', '           m_g_é_n_l', '           m_n_e_n_l', '           megyéknél', '           menyeknél', 2]\n",
      "['               c_i_i', '               _h_l_', '               _s_n_', '               chili', '               csini', 2]\n",
      "['               _h_l_', '               c_i_i', '               e_e_t', '               chili', '               ehelt', 3]\n",
      "['               b_j_a', '               _ú_n_', '               _a_t_', '               bújna', '               bajta', 2]\n",
      "['               _ú_n_', '               b_j_a', '               h_l_i', '               bújna', '               húlni', 3]\n",
      "['           k_ú_u_á_a', '           _i_j_l_s_', '           _t_l_l_s_', '           kiújulása', '           ktúlulása', 2]\n",
      "['           _i_j_l_s_', '           k_ú_u_á_a', '           k_a_e_á_t', '           kiújulása', '           kiajelást', 3]\n",
      "['          f_g_y_k_n_', '          _o_l_a_é_t', '          _e_n_a_é_t', '          foglyaként', '          fegnyaként', 2]\n",
      "['          _o_l_a_é_t', '          f_g_y_k_n_', '          k_l_t_t_s_', '          foglyaként', '          kolltatést', 5]\n",
      "['  m_n_a_é_k_l_s_g_e_', '  _u_k_n_l_ü_i_é_b_n', '  _e_k_l_t_e_e_é_b_l', '  munkanélküliségben', '  menkalétkeleségbel', 6]\n",
      "['  _u_k_n_l_ü_i_é_b_n', '  m_n_a_é_k_l_s_g_e_', '  m_n_a_e_k_l_s_g_e_', '  munkanélküliségben', '  munkanelküliségben', 1]\n",
      "['       h_t_a_ó_a_b_n', '       _a_h_t_s_b_a_', '       _a_h_t_s_t_a_', '       hathatósabban', '       hathatósatban', 1]\n",
      "['       _a_h_t_s_b_a_', '       h_t_a_ó_a_b_n', '       h_l_a_a_a_b_n', '       hathatósabban', '       halhatasabban', 2]\n"
     ]
    }
   ],
   "source": [
    "result=encoder.get_reconstruction(Xcorpus.x_test,Xcorpus,Ycorpus.x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('/mnt/store/velkey/splitbrain_200_encoding', \"a\") as myfile:\n",
    "    for it in result:\n",
    "        string=\"\"\n",
    "        for i in it:\n",
    "            string+=str(i)\n",
    "            string+='\\t'\n",
    "        string+='\\n'\n",
    "        myfile.write(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           t_l_a_a_t \t            _a_h_t_t_ \t 5\n",
      "           _ú_h_l_d_ \t            s_l_a_e_ó \t 6\n",
      "        ú_d_n_á_á_a_ \t         _l_o_t_s_b_l \t 7\n",
      "        _j_o_s_g_n_k \t         a_e_s_á_á_a_ \t 7\n",
      "               a_k_s \t                _i_á_ \t 4\n",
      "               _k_u_ \t                o_j_k \t 4\n",
      "          t_k_z_s_a_ \t           _a_s_á_b_l \t 6\n",
      "          _o_o_á_b_n \t           k_r_l_s_a_ \t 6\n",
      "          k_z_h_t_e_ \t           _s_e_e_t_k \t 6\n",
      "          _e_d_e_t_m \t           k_n_t_t_e_ \t 6\n",
      "            v_s_r_a_ \t             _a_z_b_k \t 5\n",
      "            _á_á_n_k \t             t_l_s_a_ \t 5\n",
      "       j_r_a_-_e_n_k \t        _e_e_t_t_k_e_ \t 8\n",
      "       _á_n_k_k_l_e_ \t        k_l_a_e_e_t_k \t 8\n",
      "            ö_v_n_b_ \t             _l_e_y_e \t 5\n",
      "            _r_é_y_e \t             e_m_n_r_ \t 5\n",
      "           m_g_é_n_l \t            _e_y_s_e_ \t 6\n",
      "           _e_y_k_é_ \t            m_n_e_t_l \t 6\n",
      "               c_i_i \t                _i_n_ \t 3\n",
      "               _h_l_ \t                t_e_ó \t 4\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Autoencoder_FFNN' object has no attribute 'char_accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-51c0d00ac1cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXcorpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprinter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputfsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/velkey/vahun/vahun/tools.py\u001b[0m in \u001b[0;36mshow_performance\u001b[0;34m(encoder, data, corp, length, plot, printer, inputdepth, inputfsize, encodim)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nAccuracy on data: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchar_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcharacc\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Autoencoder_FFNN' object has no attribute 'char_accuracy'"
     ]
    }
   ],
   "source": [
    "stds=show_performance(encoder,Xcorpus.x_test,Xcorpus,20,printer=True,inputdepth=20,inputfsize=len(Xcorpus.abc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 980 into shape (10,49)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-4a8b578a7f05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eh\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"kecske\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"kutya\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"aytuk\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"macska\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"árvíztűrő\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"fúró\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"kacsa\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"és\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXcorpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprinter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputfsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/velkey/vahun/vahun/tools.py\u001b[0m in \u001b[0;36mshow_performance\u001b[0;34m(encoder, data, corp, length, plot, printer, inputdepth, inputfsize, encodim)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0mcharacc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0mxa\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefeaturize_data_charlevel_onehot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputdepth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputfsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0mxb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefeaturize_data_charlevel_onehot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputdepth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputfsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mlevenshteins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLevenshtein\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxa\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 980 into shape (10,49)"
     ]
    }
   ],
   "source": [
    "std=show_performance(encoder,[\"eh\",\"kecske\",\"kutya\",\"aytuk\",\"macska\",\"árvíztűrő\",\"fúró\",\"kacsa\",\"a\",\"és\"],Xcorpus,printer=True,inputfsize=len(Xcorpus.abc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def decode_critical(lista,enc=180):\n",
    "    for POS in lista:\n",
    "        encoded=np.ones(enc)*-10\n",
    "        encoded[POS]=10\n",
    "        a=encoder.decode([encoded])[0].reshape([10,len(corpus.abc)])\n",
    "        b=corp.defeaturize_data_charlevel_onehot([a])\n",
    "        print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import heapq\n",
    "topstd=heapq.nlargest(6, range(len(stds)), stds.__getitem__)\n",
    "big_stuff=[]\n",
    "for i in range(50):\n",
    "    big_stuff.append([])\n",
    "    for topind in topstd:\n",
    "        a=encoder.encode([corpus.x_test[i]])\n",
    "        a[0][topind]=2\n",
    "        b=encoder.decode([a[0]])[0].reshape([10,len(corpus.abc)])\n",
    "        c=corpus.defeaturize_data_charlevel_onehot([b])\n",
    "        big_stuff[i].append(c)\n",
    "for row in big_stuff:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
