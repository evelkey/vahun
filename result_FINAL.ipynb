{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Experiment  Encoded_len Uniq_words  \\\n",
      "0   uniq_variational_top_uni__20170426181649          0.0     200000   \n",
      "1   uniq_variational_top_uni__20170426181649          0.0     200000   \n",
      "2   uniq_autoencoder_top_uni__20170426181705          0.0     200000   \n",
      "3   uniq_autoencoder_top_uni__20170426181705          0.0     200000   \n",
      "4   uniq_autoencoder_top_uni__20170426182211          0.0     200000   \n",
      "5   uniq_autoencoder_top_uni__20170426182211          0.0     200000   \n",
      "6   uniq_variational_top_uni__20170426182341          0.0     200000   \n",
      "7   uniq_variational_top_uni__20170426182341          0.0     200000   \n",
      "8   uniq_autoencoder_top_uni__20170426182714          0.0     200000   \n",
      "9   uniq_autoencoder_top_uni__20170426182714          0.0     200000   \n",
      "10  uniq_variational_top_uni__20170426182915          0.0     200000   \n",
      "11  uniq_variational_top_uni__20170426182915          0.0     200000   \n",
      "12  uniq_autoencoder_top_uni__20170426182925          0.0     200000   \n",
      "13  uniq_autoencoder_top_uni__20170426182925          0.0     200000   \n",
      "14  uniq_autoencoder_top_uni__20170426183223          0.0     200000   \n",
      "15  uniq_autoencoder_top_uni__20170426183223          0.0     200000   \n",
      "16  uniq_autoencoder_top_uni__20170426183350          0.0     200000   \n",
      "17  uniq_autoencoder_top_uni__20170426183350          0.0     200000   \n",
      "18  uniq_variational_top_uni__20170426183613          0.0     200000   \n",
      "19  uniq_variational_top_uni__20170426183613          0.0     200000   \n",
      "20  uniq_autoencoder_top_uni__20170426183722          0.0     200000   \n",
      "21  uniq_autoencoder_top_uni__20170426183722          0.0     200000   \n",
      "22  uniq_autoencoder_top_uni__20170426183820          0.0     200000   \n",
      "23  uniq_autoencoder_top_uni__20170426183820          0.0     200000   \n",
      "24  uniq_autoencoder_top_uni__20170426184232          0.0     200000   \n",
      "25  uniq_autoencoder_top_uni__20170426184232          0.0     200000   \n",
      "26  uniq_autoencoder_top_uni__20170426184251          0.0     200000   \n",
      "27  uniq_autoencoder_top_uni__20170426184251          0.0     200000   \n",
      "28  uniq_variational_top_uni__20170426184258          0.0     200000   \n",
      "29  uniq_variational_top_uni__20170426184258          0.0     200000   \n",
      "30  uniq_autoencoder_top_uni__20170426184729          0.0     200000   \n",
      "31  uniq_autoencoder_top_uni__20170426184729          0.0     200000   \n",
      "32  uniq_autoencoder_top_uni__20170426184735          0.0     200000   \n",
      "33  uniq_autoencoder_top_uni__20170426184735          0.0     200000   \n",
      "34  uniq_variational_top_uni__20170426184955          0.0     200000   \n",
      "\n",
      "   Variational  Uniq  Layernum  Train_char_acc  Valid_char_acc  Test_char_acc  \\\n",
      "0         True  True         2        0.699399        0.698318       0.701747   \n",
      "1         True  True         2        0.699329        0.698235       0.701557   \n",
      "2        False  True         2        0.696825        0.696345       0.694913   \n",
      "3        False  True         2        0.695728        0.695835       0.694362   \n",
      "4        False  True         2        0.766488        0.765912       0.764868   \n",
      "5        False  True         2        0.765310        0.764845       0.763818   \n",
      "6         True  True         2        0.766905        0.765960       0.768895   \n",
      "7         True  True         2        0.766304        0.765430       0.768230   \n",
      "8        False  True         2        0.815684        0.814975       0.813835   \n",
      "9        False  True         2        0.815565        0.815110       0.814045   \n",
      "10        True  True         2        0.812797        0.812333       0.814685   \n",
      "11        True  True         2        0.812692        0.812187       0.814473   \n",
      "12       False  True         4        0.793466        0.792432       0.792952   \n",
      "13       False  True         4        0.800906        0.799380       0.801033   \n",
      "14       False  True         2        0.848580        0.847882       0.846850   \n",
      "15       False  True         2        0.849468        0.848598       0.847935   \n",
      "16       False  True         4        0.802851        0.801817       0.802702   \n",
      "17       False  True         4        0.807402        0.805930       0.806933   \n",
      "18        True  True         2        0.847447        0.846897       0.849120   \n",
      "19        True  True         2        0.847630        0.846988       0.849380   \n",
      "20       False  True         2        0.879867        0.878848       0.878408   \n",
      "21       False  True         2        0.879648        0.878698       0.878255   \n",
      "22       False  True         4        0.805708        0.804340       0.805593   \n",
      "23       False  True         4        0.804753        0.803462       0.804272   \n",
      "24       False  True         2        0.901023        0.899970       0.899540   \n",
      "25       False  True         2        0.900562        0.899625       0.899203   \n",
      "26       False  True         4        0.809498        0.808140       0.809435   \n",
      "27       False  True         4        0.807624        0.806068       0.807183   \n",
      "28        True  True         2        0.877074        0.876700       0.878865   \n",
      "29        True  True         2        0.877083        0.876517       0.879000   \n",
      "30       False  True         4        0.814239        0.812697       0.813875   \n",
      "31       False  True         4        0.810113        0.808420       0.810175   \n",
      "32       False  True         2        0.917514        0.916438       0.916273   \n",
      "33       False  True         2        0.917470        0.916390       0.916277   \n",
      "34        True  True         2        0.897429        0.896825       0.899030   \n",
      "\n",
      "    Test_word_acc  Test_Leven_avg  Train_Leven_avg  Valid_Leven_avg  \\\n",
      "0         0.00075         5.95695         5.995712          6.01855   \n",
      "1         0.00095         5.95830         5.997044          6.02055   \n",
      "2         0.00055         6.08910         6.050719          6.06110   \n",
      "3         0.00055         6.09915         6.072012          6.07010   \n",
      "4         0.00720         4.69485         4.663012          4.67475   \n",
      "5         0.00715         4.71560         4.687056          4.69625   \n",
      "6         0.00715         4.61985         4.650450          4.67370   \n",
      "7         0.00650         4.62915         4.664187          4.68760   \n",
      "8         0.02470         3.71915         3.682937          3.69745   \n",
      "9         0.02450         3.71555         3.685225          3.69505   \n",
      "10        0.02450         3.70040         3.734394          3.74950   \n",
      "11        0.02485         3.70435         3.735806          3.74955   \n",
      "12        0.01410         4.13075         4.121738          4.14135   \n",
      "13        0.01685         3.97285         3.975375          4.00590   \n",
      "14        0.05440         3.06010         3.025913          3.03985   \n",
      "15        0.05565         3.03855         3.008200          3.02600   \n",
      "16        0.01845         3.93800         3.935069          3.95530   \n",
      "17        0.02090         3.85445         3.845844          3.87505   \n",
      "18        0.05465         3.01005         3.039200          3.05745   \n",
      "19        0.05320         3.00650         3.037288          3.05815   \n",
      "20        0.11390         2.43085         2.401425          2.42185   \n",
      "21        0.11265         2.43390         2.405931          2.42500   \n",
      "22        0.02010         3.88005         3.878594          3.90560   \n",
      "23        0.01925         3.90755         3.897744          3.92185   \n",
      "24        0.17550         2.00815         1.978163          1.99915   \n",
      "25        0.17390         2.01465         1.987344          2.00580   \n",
      "26        0.02350         3.80435         3.802719          3.82940   \n",
      "27        0.02000         3.84710         3.839081          3.87055   \n",
      "28        0.11045         2.41805         2.447331          2.46560   \n",
      "29        0.11050         2.42050         2.446737          2.46520   \n",
      "30        0.02290         3.71540         3.708325          3.73775   \n",
      "31        0.02190         3.78885         3.790062          3.82365   \n",
      "32        0.25395         1.67335         1.648556          1.66975   \n",
      "33        0.25545         1.67320         1.649400          1.67080   \n",
      "34        0.17170         2.02000         2.041794          2.06160   \n",
      "\n",
      "                 Layers  \n",
      "0             [20, 960]  \n",
      "1             [20, 960]  \n",
      "2             [20, 960]  \n",
      "3             [20, 960]  \n",
      "4             [40, 960]  \n",
      "5             [40, 960]  \n",
      "6             [40, 960]  \n",
      "7             [40, 960]  \n",
      "8             [60, 960]  \n",
      "9             [60, 960]  \n",
      "10            [60, 960]  \n",
      "11            [60, 960]  \n",
      "12  [220, 20, 220, 960]  \n",
      "13  [220, 20, 220, 960]  \n",
      "14            [80, 960]  \n",
      "15            [80, 960]  \n",
      "16  [260, 20, 260, 960]  \n",
      "17  [260, 20, 260, 960]  \n",
      "18            [80, 960]  \n",
      "19            [80, 960]  \n",
      "20           [100, 960]  \n",
      "21           [100, 960]  \n",
      "22  [300, 20, 300, 960]  \n",
      "23  [300, 20, 300, 960]  \n",
      "24           [120, 960]  \n",
      "25           [120, 960]  \n",
      "26  [340, 20, 340, 960]  \n",
      "27  [340, 20, 340, 960]  \n",
      "28           [100, 960]  \n",
      "29           [100, 960]  \n",
      "30  [380, 20, 380, 960]  \n",
      "31  [380, 20, 380, 960]  \n",
      "32           [140, 960]  \n",
      "33           [140, 960]  \n",
      "34           [120, 960]  \n"
     ]
    }
   ],
   "source": [
    "from vahun.LogReader import LogReader\n",
    "import pandas as pd\n",
    "log=LogReader()\n",
    "table=log.get_full_table()\n",
    "table.to_csv('/mnt/store/velkey/result_full.tsv',sep='\\t')\n",
    "print(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
