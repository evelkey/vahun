{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from vahun.Text import Text\n",
    "import numpy as np\n",
    "from vahun.tools import Timer\n",
    "from vahun.tools import explog\n",
    "from vahun.autoencoder import Autoencoder_ffnn\n",
    "from vahun.variational_autoencoder import Variational_autoencoder\n",
    "from vahun.genetic import evolution\n",
    "from vahun.genetic import experiment\n",
    "from vahun.tools import show_performance\n",
    "from vahun.genetic import Settings\n",
    "\n",
    "timer=Timer()\n",
    "\n",
    "size=200000\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "corpuses=[Text(corpus_path='/mnt/store/velkey/mnsz2/filt.200k.maxlen20'),\n",
    "          Text(corpus_path='/mnt/store/velkey/mnsz2/filt.200k_random.maxlen20'),\n",
    "          Text(corpus_path='/mnt/store/velkey/mnsz2/filt.200k.maxlen20.digraph_repl'),\n",
    "          Text(corpus_path='/mnt/store/velkey/mnsz2/filt.200k_random.maxlen20.digraph_repl')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting experiment:  [1, 0, 0, 220, 960]\n"
     ]
    }
   ],
   "source": [
    "exps = []\n",
    "ranger=range(10,20)\n",
    "i=0\n",
    "with open('/mnt/store/velkey/experiments') as f:\n",
    "    for line in f:\n",
    "        if(i in ranger):\n",
    "            exps.append(line.strip().split('\\t'))\n",
    "        i+=1\n",
    "\n",
    "\n",
    "for exper in exps:\n",
    "    exper=[int(item) for item in exper]\n",
    "    layerlist=exper[3:]\n",
    "    settings=Settings(layerlist)\n",
    "    if exper[1]==0 and exper[2]==0:\n",
    "        corpus_path='/mnt/store/velkey/mnsz2/filt.200k.maxlen20'\n",
    "        typ=0\n",
    "    if exper[1]==1 and exper[2]==0:\n",
    "        corpus_path='/mnt/store/velkey/mnsz2/filt.200k_random.maxlen20'\n",
    "        typ=1\n",
    "    if exper[1]==0 and exper[2]==1:\n",
    "        corpus_path='/mnt/store/velkey/mnsz2/filt.200k.maxlen20.digraph_repl'\n",
    "        typ=2\n",
    "    if exper[1]==1 and exper[2]==1:\n",
    "        corpus_path='/mnt/store/velkey/mnsz2/filt.200k_random.maxlen20.digraph_repl'\n",
    "        typ=3\n",
    "    \n",
    "    corpus=corpuses[typ]\n",
    "    name=(str(\"uniq_\"+(\"variational_\" if exper[0]==1 else \"autoencoder_\")+\n",
    "                    (\"top_\" if exper[1]==1 else \"random_\")+\n",
    "                    (\"bigraph_\" if exper[2]==1 else \"uni_\")))\n",
    "    logger=explog(encoder_type=name,\n",
    "              encoding_dim=0,\n",
    "              feature_len=20,\n",
    "              lang=corpus_path,\n",
    "              unique_words=len(set(corpus.wordlist)),\n",
    "              name=name,\n",
    "              population_size=0,\n",
    "              words=len(corpus.wordlist))\n",
    "    print(\"starting experiment: \",exper)\n",
    "    timer.add(\"experiment\")\n",
    "    \n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.Session(config=config)\n",
    "    \n",
    "    if(exper[0]==1):\n",
    "        encoder=Variational_autoencoder(logger=logger,\n",
    "                                        tf_session=sess,\n",
    "                                        inputdim=len(corpus.abc)*20,\n",
    "                                        encoding_size=settings.weights[0],\n",
    "                                        corpus=corpus,\n",
    "                                        optimizer =tf.train.AdamOptimizer(learning_rate = 0.001),\n",
    "                                        nonlinear=tf.sigmoid)\n",
    "    else:\n",
    "        encoder=Autoencoder_ffnn(\n",
    "                         experiment=settings,\n",
    "                         logger = logger,\n",
    "                         tf_session=sess,\n",
    "                         inputdim = len(corpus.abc)*20,\n",
    "                         layerlist = settings.weights,\n",
    "                         encode_index = int(len(settings.weights)/2),\n",
    "                         corpus = corpus,\n",
    "                         optimizer = tf.train.AdamOptimizer(learning_rate = 0.001),\n",
    "                         nonlinear = tf.sigmoid,\n",
    "                         charnum=len(corpus.abc))\n",
    "    \n",
    "    encoder.train(corpus.x_train,corpus.x_valid,corpus.x_test,512,80)\n",
    "    \n",
    "    print(\"Finished in:\", timer.get(\"experiment\") ,\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
