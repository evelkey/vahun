{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from vahun.corpus import TSV_Corpus as Corpus\n",
    "import numpy as np\n",
    "from vahun.tools import Timer\n",
    "from vahun.tools import explog\n",
    "#from vahun.autoencoder import Autoencoder_ffnn\n",
    "from vahun.tools import show_performance\n",
    "from vahun.genetic import Settings\n",
    "from vahun.tools import get_reconstruction\n",
    "\n",
    "from vahun.Autoencoder_FFNN import Autoencoder_FFNN\n",
    "from vahun.Autoencoder_Variational import Autoencoder_Variational\n",
    "timer=Timer()\n",
    "\n",
    "\n",
    "\n",
    "size=400000\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from vahun.corpus import TrainXY_Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "arg=TrainXY_Corpus('/mnt/store/velkey/mnsz2/webcorp.full.enfilt.segmented',size=400000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' +-.abCcdDeEfGghijklLmNnopqrsStTuvwxyZzáéíóöúüőű'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "\n",
    "def levennoise(corpus,word,dist=2):\n",
    "    if len(word)>18:\n",
    "        return word\n",
    "    for i in range(dist):\n",
    "        a=random.random()\n",
    "        if a <= 0.333:\n",
    "            #del\n",
    "            r=random.randint(0,len(word))\n",
    "            word=word[:r]+word[r+1:]\n",
    "        if a>0.333 and a<=0.666:\n",
    "            #append\n",
    "            r=random.randint(0,len(word))\n",
    "            x=random.randint(0,len(corpus.abc))-1\n",
    "            ch=list(corpus.abc)[x]\n",
    "            word=word[:r]+ch+word[r:]\n",
    "        if a>0.666:\n",
    "            #change\n",
    "            r=random.randint(0,len(word))\n",
    "            x=random.randint(0,len(corpus.abc))-1\n",
    "            ch=list(corpus.abc)[x]\n",
    "            word=word[:r]+ch+word[r+1:]\n",
    "    return word\n",
    "def levenshtein_noisify(corpus):\n",
    "    wordlist=[levennoise(corpus,word) for word in corpus.wordlist]\n",
    "    return wordlist,corpus.featurize_data_charlevel_onehot(wordlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "levenwords,X_leven=levenshtein_noisify(corpuses[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting experiment:  [1, 0, 0, 220, 960]\n",
      "Finished in: 159.96761083602905 s\n",
      "starting experiment:  [1, 0, 0, 220, 960]\n",
      "Finished in: 154.55685210227966 s\n",
      "starting experiment:  [1, 0, 0, 240, 960]\n",
      "Finished in: 152.683039188385 s\n",
      "starting experiment:  [1, 0, 0, 240, 960]\n",
      "Finished in: 155.1431360244751 s\n",
      "starting experiment:  [1, 0, 0, 260, 960]\n",
      "Finished in: 169.9944987297058 s\n",
      "starting experiment:  [1, 0, 0, 260, 960]\n",
      "Finished in: 168.34088492393494 s\n",
      "starting experiment:  [1, 0, 0, 280, 960]\n",
      "Finished in: 165.04826188087463 s\n",
      "starting experiment:  [1, 0, 0, 280, 960]\n",
      "Finished in: 160.5538728237152 s\n",
      "starting experiment:  [1, 0, 0, 300, 960]\n",
      "Finished in: 165.71419978141785 s\n",
      "starting experiment:  [1, 0, 0, 300, 960]\n"
     ]
    }
   ],
   "source": [
    "exps = []\n",
    "ranger=range(10,20)\n",
    "i=0\n",
    "with open('/mnt/store/velkey/experiments') as f:\n",
    "    for line in f:\n",
    "        if(i in ranger):\n",
    "            exps.append(line.strip().split('\\t'))\n",
    "        i+=1\n",
    "\n",
    "\n",
    "for exper in exps:\n",
    "    exper=[int(item) for item in exper]\n",
    "    layerlist=exper[3:]\n",
    "    settings=Settings(layerlist)\n",
    "    typ=0\n",
    "    if exper[1]==0 and exper[2]==0:\n",
    "        corpus_path='/mnt/store/velkey/mnsz2/filt.200k.maxlen20'\n",
    "        typ=0\n",
    "    if exper[1]==1 and exper[2]==0:\n",
    "        corpus_path='/mnt/store/velkey/mnsz2/filt.200k_random.maxlen20'\n",
    "        typ=1\n",
    "    if exper[1]==0 and exper[2]==1:\n",
    "        corpus_path='/mnt/store/velkey/mnsz2/filt.200k.maxlen20.digraph_repl'\n",
    "        typ=2\n",
    "    if exper[1]==1 and exper[2]==1:\n",
    "        corpus_path='/mnt/store/velkey/mnsz2/filt.200k_random.maxlen20.digraph_repl'\n",
    "        typ=3\n",
    "    \n",
    "    corpus=corpuses[typ]\n",
    "    name=(str(\"uniq_\"+(\"variational_\" if exper[0]==1 else \"autoencoder_\")+\n",
    "                    (\"top_\" if exper[1]==1 else \"random_\")+\n",
    "                    (\"bigraph_\" if exper[2]==1 else \"uni_\")))\n",
    "    logger=explog(encoder_type=name,\n",
    "              encoding_dim=0,\n",
    "              feature_len=20,\n",
    "              lang=corpus_path,\n",
    "              unique_words=len(set(corpus.wordlist)),\n",
    "              name=name,\n",
    "              population_size=0,\n",
    "              words=len(corpus.wordlist))\n",
    "    for k in range(2):\n",
    "        print(\"starting experiment: \",exper)\n",
    "        timer.add(\"experiment\")\n",
    "\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        sess = tf.Session(config=config)\n",
    "\n",
    "        if(exper[0]==1):\n",
    "            encoder=Variational_autoencoder(logger=logger,\n",
    "                                            tf_session=sess,\n",
    "                                            inputdim=len(corpus.abc)*20,\n",
    "                                            encoding_size=settings.weights[0],\n",
    "                                            corpus=corpus,\n",
    "                                            optimizer =tf.train.AdamOptimizer(learning_rate = 0.001),\n",
    "                                            nonlinear=tf.sigmoid,charnum=len(corpus.abc))\n",
    "\n",
    "\n",
    "        else:\n",
    "            encoder=Autoencoder_ffnn(\n",
    "                             experiment=settings,\n",
    "                             logger = logger,\n",
    "                             tf_session=sess,\n",
    "                             inputdim = len(corpus.abc)*20,\n",
    "                             layerlist = settings.weights,\n",
    "                             encode_index = int(len(settings.weights)/2),\n",
    "                             corpus = corpus,\n",
    "                             optimizer = tf.train.AdamOptimizer(learning_rate = 0.001),\n",
    "                             nonlinear = tf.sigmoid,\n",
    "                             charnum=len(corpus.abc))\n",
    "\n",
    "        encoder.train(corpus.x_train,corpus.x_valid,corpus.x_test,512,80)\n",
    "    \n",
    "        print(\"Finished in:\", timer.get(\"experiment\") ,\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
