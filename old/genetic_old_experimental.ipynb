{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus initalized, fields: ['unique', 'lower', 'hun_lower', 'lower_unique', 'hun_lower_unique'] \n",
      "Unique words:  25545\n",
      "(60152, 360)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction=1\n",
    "\n",
    "import time\n",
    "import collections\n",
    "import scipy\n",
    "from corpus import Corpus\n",
    "import numpy as np\n",
    "from random import randint, random\n",
    "\n",
    "\n",
    "def xavier_init(fan_in, fan_out, constant = 1):\n",
    "    low = -constant * np.sqrt(6.0 / (fan_in + fan_out))\n",
    "    high = constant * np.sqrt(6.0 / (fan_in + fan_out))\n",
    "    return tf.random_uniform((fan_in, fan_out),\n",
    "                             minval = low, maxval = high,\n",
    "                             dtype = tf.float32)\n",
    "\n",
    "corp_path='/home/velkey/corp/webkorpusz.wpl'\n",
    "corp=Corpus(corpus_path=corp_path,language=\"Hun\",size=100000,encoding_len=10)\n",
    "all_features=corp.featurize_data_charlevel_onehot(corp.hun_lower)\n",
    "train=all_features[0:int(len(all_features)*0.8)]\n",
    "test=all_features[int(len(all_features)*0.8):len(all_features)]\n",
    "x_train = train.reshape((len(train), np.prod(train.shape[1:])))\n",
    "x_test = test.reshape((len(test), np.prod(test.shape[1:])))\n",
    "print(x_train.shape)\n",
    "\n",
    "class Timer:\n",
    "    def __init__(self):\n",
    "        self.timers=dict()\n",
    "    def add(self,str):\n",
    "        self.timers[str]=time.time()\n",
    "    def get(self,str):\n",
    "        return time.time()-self.timers[str]\n",
    "timer=Timer()\n",
    "\n",
    "def logtsv(array):\n",
    "    string=\"\"\n",
    "    for item in array:\n",
    "        string+=str(item)\n",
    "        string+=\"\\t\"\n",
    "    string=string[0:len(string)-1]+\"\\n\"\n",
    "    with open(\"train.tsv\", \"a\") as myfile:\n",
    "        myfile.write(string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Autoencoder_ffnn():\n",
    "    def __init__(self,experiment,tf_session, inputdim,layerlist,encode_index,optimizer = tf.train.AdamOptimizer(),nonlinear=tf.nn.relu):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.experiment=experiment\n",
    "        \n",
    "        self.layerlist=layerlist\n",
    "        self.layernum=len(layerlist)\n",
    "        self.n_input = inputdim\n",
    "        self.encode_index=encode_index\n",
    "        self.display_step=10\n",
    "\n",
    "        network_weights = self._initialize_weights()\n",
    "        self.weights = network_weights  \n",
    "\n",
    "        self._create_layers(nonlinear)\n",
    "\n",
    "        # cost\n",
    "        self.cost =  0.5*tf.reduce_sum(tf.pow(tf.subtract(self.reconstruction, self.x), 2.0))\n",
    "        self.optimizer = optimizer.minimize(self.cost)\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess = tf_session\n",
    "        self.sess.run(init)\n",
    "        \n",
    "        self.size=0\n",
    "        nums=[self.n_input,layerlist]\n",
    "        for i in range(1,len(nums)):\n",
    "            self.size+=4*layerlist[i]*layerlist[i-1]\n",
    "        \n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        all_weights = dict()\n",
    "        \n",
    "        all_weights['w1']=tf.Variable(xavier_init(self.n_input, self.layerlist[0]))\n",
    "        all_weights['b1'] = tf.Variable(tf.random_normal([self.layerlist[0]], dtype=tf.float32))\n",
    "        \n",
    "        for i in range(1,self.layernum):\n",
    "            all_weights['w'+str(i+1)]=tf.Variable(xavier_init(self.layerlist[i-1], self.layerlist[i]))\n",
    "            all_weights['b'+str(i+1)] = tf.Variable(tf.random_normal([self.layerlist[i]], dtype=tf.float32))\n",
    "\n",
    "        return all_weights\n",
    "    \n",
    "    def _create_layers(self,nonlinearity=tf.nn.relu):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.x = tf.placeholder(tf.float32, [None, self.n_input])\n",
    "        layer=nonlinearity(tf.add(tf.matmul(self.x, self.weights['w1']), self.weights['b1']))\n",
    "\n",
    "        for i in range(1,self.layernum-1):\n",
    "            if i==self.encode_index:\n",
    "                self.encoded=layer\n",
    "            layer=nonlinearity(tf.add(tf.matmul(layer, self.weights['w'+str(i+1)]), self.weights['b'+str(i+1)]))\n",
    "            \n",
    "        self.reconstruction=tf.add(tf.matmul(layer, self.weights['w'+str(self.layernum)]), self.weights['b'+str(self.layernum)])\n",
    "\n",
    "    def partial_fit(self, X):\n",
    "        cost, opt = self.sess.run((self.cost, self.optimizer), feed_dict={self.x: X})\n",
    "        return cost\n",
    "\n",
    "    def calc_total_cost(self, X):\n",
    "        return self.sess.run(self.cost, feed_dict = {self.x: X})\n",
    "\n",
    "    def encode(self, X):\n",
    "        return self.sess.run(self.encoded, feed_dict={self.x: X})\n",
    "\n",
    "    def decode(self, encoded = None):\n",
    "        if encoded is None:\n",
    "            encoded = np.random.normal(size=self.weights[\"b1\"])\n",
    "        return self.sess.run(self.reconstruction, feed_dict={self.encoded: encoded})\n",
    "\n",
    "    def reconstruct(self, X):\n",
    "        return self.sess.run(self.reconstruction, feed_dict={self.x: X})\n",
    "    \n",
    "    def train(self,X_train,X_test,batch_size,max_epochs):\n",
    "        breaker=False\n",
    "        testlog=collections.deque(maxlen=30)\n",
    "        \n",
    "        for epoch in range(max_epochs):\n",
    "            avg_cost = 0.\n",
    "            total_batch = int(len(X_train) / batch_size)\n",
    "            # Loop over all batches\n",
    "            for i in range(total_batch):\n",
    "                batch_xs = self.get_random_block_from_data(X_train, batch_size)\n",
    "                cost = self.partial_fit(batch_xs)\n",
    "                avg_cost += cost/ batch_size\n",
    "                \n",
    "                #early stop\n",
    "                testlog.append(self.calc_total_cost(X_test))\n",
    "                for i in range(8):\n",
    "                    if len(testlog)>20 and testlog[-i]>=testlog[-10-i]*0.995:\n",
    "                        breaker=True\n",
    "                    else:\n",
    "                        breaker=False\n",
    "                if breaker:\n",
    "                    print(\"STOPPED OVERFIT\")\n",
    "                    break\n",
    "            # Display logs per epoch step\n",
    "            if epoch % self.display_step == 0:\n",
    "                print (\"Epoch:\", '%04d' % (epoch + 1), \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "            if breaker:\n",
    "                break\n",
    "                \n",
    "    def get_random_block_from_data(self,data, batch_size):\n",
    "        start_index = np.random.randint(0, len(data) - batch_size)\n",
    "        return data[start_index:(start_index + batch_size)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class experiment:\n",
    "    \n",
    "    def __init__(self,out_dim,minw,maxw,encoded_width,layermin=1,layermax=5):\n",
    "        self.len=randint(layermin,layermax)*2\n",
    "        self.weights=[randint(minw,maxw) for n in range(self.len)]\n",
    "        self.weights[int(self.len/2-1)]=encoded_width\n",
    "        self.weights[-1]=out_dim\n",
    "        \n",
    "    def set(self,weights):\n",
    "        self.len=len(weights)\n",
    "        self.weights=weights\n",
    "        \n",
    "class evolution:\n",
    "    \n",
    "    def __init__(self,x_train,x_test,population_size,encoder,dim,repeat_runs=2,epoch=30,batch=512,disp_freq=1):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.encoded_width=encoder\n",
    "        self.dim=dim\n",
    "        self.min=10\n",
    "        self.max=200\n",
    "        self.repeat_runs=repeat_runs\n",
    "        \n",
    "        self.training_epochs = epoch\n",
    "        self.batch_size = batch\n",
    "        self.display_step = disp_freq\n",
    "        self.x_train=x_train\n",
    "        self.x_test=x_test\n",
    "        \n",
    "        self.learnrate=0.001\n",
    "        self.batchsize=512\n",
    "        self.maxepoch=100\n",
    "        self.optimizer=tf.train.AdamOptimizer(learning_rate = self.learnrate)\n",
    "        \n",
    "        \n",
    "        self.retain_p=0.2\n",
    "        self.random_select_p=0.05\n",
    "        self.mutate_p=0.1\n",
    "        self.mutate_len_p=0.1\n",
    "        self.mutate_width_p=0.4\n",
    "        self.population_size=population_size\n",
    "        self.population=self.gen_population(population_size)\n",
    "        \n",
    "        self.target=0\n",
    "        \n",
    "\n",
    "        \n",
    "    def ekv(self,e):\n",
    "        return e\n",
    "       \n",
    "    \n",
    "    def gen_population(self,count):\n",
    "        \"\"\"\n",
    "        count: the number of individuals in the population\n",
    "        \"\"\"\n",
    "        self.sess = tf.Session(config=config)\n",
    "        \n",
    "        population=[]\n",
    "        for x in range(count):\n",
    "            exp=experiment(out_dim=self.dim,minw=self.min,maxw=self.max,encoded_width=self.encoded_width)\n",
    "            population.append(Autoencoder_ffnn(experiment=exp,tf_session=self.sess,inputdim=self.dim,layerlist=exp.weights,\n",
    "                                               encode_index=int(exp.len/2-1),\n",
    "                                               optimizer = self.optimizer))\n",
    "        return population\n",
    "    \n",
    "    def new_generation(self,experiments):\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        self.sess.close()\n",
    "        self.sess = tf.Session(config=config)\n",
    "        \n",
    "        print(\"New generation is being created.\")\n",
    "        \n",
    "        population=[]\n",
    "        for x in range(len(experiments)):\n",
    "    \n",
    "            population.append(Autoencoder_ffnn(experiment=experiments[x],tf_session=self.sess,inputdim=self.dim,layerlist=experiments[x].weights,\n",
    "                                               encode_index=int(experiments[x].len/2-1),\n",
    "                                               optimizer = self.optimizer))\n",
    "        return population\n",
    "    \n",
    "    def train_population(self):\n",
    "        self.population_fitness=[]\n",
    "        for individual in self.population:\n",
    "            sum_cost=0\n",
    "            for i in range(self.repeat_runs): #average the model's fitness\n",
    "                individual.train(self.x_train,x_test,self.batchsize,self.maxepoch)\n",
    "                sum_cost+=individual.calc_total_cost(self.x_test)\n",
    "            self.population_fitness.append(sum_cost/self.repeat_runs)\n",
    "        return self.population_fitness\n",
    "    \n",
    "\n",
    "    def grade(self):\n",
    "        'Find average fitness for a population.'\n",
    "        summed = sum(self.population_fitness)\n",
    "        self.graded= summed / (self.population_size * 1.0)\n",
    "        return self.graded\n",
    "    \n",
    "    def mutate(self,group):\n",
    "        for individual in group:\n",
    "            if self.mutate_p > random():\n",
    "                if self.mutate_len_p>random():\n",
    "                    if random()<0.5:\n",
    "                        individual.len+=2\n",
    "                        individual.weights=[randint(self.min, self.max),randint(self.min, self.max)]+individual.weights\n",
    "                        individual.weights[int(individual.len/2-1)]=self.encoded_width\n",
    "                    else :\n",
    "                        if individual.len!=2:\n",
    "                            individual.len-=2\n",
    "                            individual.weights=individual.weights[2:]\n",
    "                            individual.weights[int(individual.len/2-1)]=self.encoded_width\n",
    "                if self.mutate_width_p>random():\n",
    "                    pos_to_mutate = randint(0,individual.len-2)\n",
    "                    if pos_to_mutate!=int(individual.len/2-1):\n",
    "                        if 0.5>random():\n",
    "                            individual.weights[pos_to_mutate] +=20\n",
    "                        else:\n",
    "                            individual.weights[pos_to_mutate] -=20\n",
    "        self.mutants=group\n",
    "        return group\n",
    "\n",
    "    def evolve(self):\n",
    "        self.train_population()\n",
    "        \n",
    "        #select top individs\n",
    "        graded = [(self.population_fitness[x], self.population[x].experiment) for x in range(self.population_size)]\n",
    "        graded = [ x[1] for x in sorted(graded)]\n",
    "        retain_length = int(len(graded)*self.retain_p)\n",
    "        parents = graded[:retain_length]\n",
    "        \n",
    "        \n",
    "        # randomly add other individuals to\n",
    "        # promote genetic diversity\n",
    "        for individual in graded[retain_length:]:\n",
    "            if self.random_select_p > random():\n",
    "                parents.append(individual)\n",
    "        \n",
    "        # mutate \n",
    "        mutants=self.mutate(parents)\n",
    "       \n",
    "        # crossover parents to create children (aka sex)\n",
    "        mutants_length = len(mutants)\n",
    "        desired_length = self.population_size - mutants_length\n",
    "        children = []\n",
    "        while len(children) < desired_length:\n",
    "            male = randint(0, mutants_length-1)\n",
    "            female = randint(0, mutants_length-1)\n",
    "            if male != female:\n",
    "                male = mutants[male]\n",
    "                female = mutants[female]\n",
    "                \n",
    "                child=experiment(out_dim=self.dim,minw=self.min,maxw=self.max,encoded_width=self.encoded_width)\n",
    "                weights = male.weights[:int(male.len/2-1)]+female.weights[int(female.len/2-1):]\n",
    "                child.set(weights)\n",
    "                children.append(child)\n",
    "                \n",
    "        mutants.extend(children)\n",
    "        \n",
    "        self.population=self.new_generation(mutants)\n",
    "        return mutants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c02a27733344>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevolution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m360\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "x=evolution(x_train,x_test,80,100,360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[187, 128, 190, 100, 119, 177, 103, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[78, 28, 185, 163, 100, 79, 49, 53, 126, 360]\n",
      "[108, 162, 57, 144, 100, 64, 169, 52, 135, 360]\n",
      "[196, 173, 10, 100, 14, 80, 180, 360]\n",
      "[32, 105, 74, 191, 100, 27, 184, 34, 177, 360]\n",
      "[35, 74, 38, 18, 100, 61, 44, 171, 186, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[173, 83, 70, 100, 149, 48, 28, 360]\n",
      "[68, 161, 39, 100, 14, 89, 14, 360]\n",
      "[79, 57, 91, 100, 139, 12, 136, 360]\n",
      "[15, 100, 111, 360]\n",
      "[100, 360]\n",
      "[21, 100, 157, 360]\n",
      "[192, 115, 100, 62, 74, 360]\n",
      "[101, 70, 126, 168, 100, 15, 152, 117, 113, 360]\n",
      "[66, 75, 86, 71, 100, 89, 11, 167, 17, 360]\n",
      "[146, 21, 74, 100, 18, 86, 62, 360]\n",
      "[65, 75, 149, 100, 97, 153, 200, 360]\n",
      "[100, 360]\n",
      "[68, 100, 153, 360]\n",
      "[160, 123, 151, 182, 100, 52, 158, 184, 136, 360]\n",
      "[100, 360]\n",
      "[27, 100, 61, 360]\n",
      "[32, 56, 118, 120, 100, 56, 71, 77, 28, 360]\n",
      "[100, 360]\n",
      "[11, 69, 33, 183, 100, 187, 163, 124, 93, 360]\n",
      "[23, 164, 100, 91, 44, 360]\n",
      "[66, 101, 100, 29, 16, 360]\n",
      "[47, 198, 162, 147, 100, 165, 77, 124, 94, 360]\n",
      "[164, 89, 187, 100, 194, 146, 35, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[166, 24, 33, 100, 45, 99, 91, 360]\n",
      "[121, 67, 100, 154, 123, 360]\n",
      "[140, 80, 19, 100, 159, 165, 57, 360]\n",
      "[200, 100, 141, 360]\n",
      "[47, 26, 142, 100, 113, 134, 48, 360]\n",
      "[185, 124, 124, 100, 83, 169, 159, 360]\n",
      "[40, 159, 195, 193, 100, 28, 48, 83, 14, 360]\n",
      "[100, 360]\n",
      "[27, 108, 100, 135, 76, 360]\n",
      "[185, 20, 61, 114, 100, 32, 104, 170, 153, 360]\n",
      "[100, 360]\n",
      "[183, 100, 12, 360]\n",
      "[70, 39, 194, 100, 159, 128, 79, 360]\n",
      "[100, 360]\n",
      "[193, 75, 186, 100, 83, 186, 17, 360]\n",
      "[170, 35, 52, 100, 40, 149, 112, 360]\n",
      "[70, 64, 100, 24, 181, 360]\n",
      "[100, 360]\n",
      "[145, 35, 168, 100, 160, 37, 110, 360]\n",
      "[138, 186, 113, 100, 169, 190, 10, 360]\n",
      "[22, 181, 147, 100, 195, 14, 53, 360]\n",
      "[154, 166, 100, 166, 141, 360]\n",
      "[64, 100, 170, 360]\n",
      "[108, 52, 85, 100, 93, 76, 187, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[19, 120, 100, 75, 150, 360]\n",
      "[86, 61, 100, 55, 171, 360]\n",
      "[148, 67, 146, 170, 100, 175, 188, 169, 130, 360]\n",
      "[99, 101, 100, 66, 26, 360]\n",
      "[171, 77, 36, 180, 100, 23, 130, 71, 95, 360]\n",
      "[196, 100, 88, 360]\n",
      "[103, 89, 57, 100, 134, 193, 120, 360]\n",
      "[105, 198, 64, 131, 100, 139, 47, 43, 134, 360]\n",
      "[59, 92, 123, 100, 192, 77, 168, 360]\n",
      "[84, 83, 100, 152, 148, 360]\n",
      "[100, 360]\n",
      "[21, 50, 83, 100, 140, 104, 200, 360]\n",
      "[100, 360]\n",
      "[168, 137, 19, 19, 100, 125, 143, 196, 27, 360]\n",
      "[76, 195, 61, 64, 100, 171, 49, 35, 23, 360]\n",
      "[31, 100, 128, 360]\n",
      "[37, 100, 67, 360]\n",
      "[100, 360]\n",
      "[165, 91, 33, 100, 16, 37, 192, 360]\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 2367.262086391\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 101.842037201\n",
      "Epoch: 0001 cost= 2222.901229143\n",
      "STOPPED OVERFIT\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 40.376818180\n",
      "Epoch: 0001 cost= 1498.755828857\n",
      "STOPPED OVERFIT\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 47.165527582\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 1164.144130468\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 62.841074944\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 1138.764196157\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 63.628291130\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 1047.222422123\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 63.697357893\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 1028.531661749\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 64.081914663\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 917.734226465\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 63.386874199\n",
      "Epoch: 0001 cost= 1460.549552441\n",
      "STOPPED OVERFIT\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 33.388400674\n",
      "Epoch: 0001 cost= 1324.388271570\n",
      "STOPPED OVERFIT\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 32.825429440\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 1527.400264025\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 62.744399071\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 1705.818437576\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 63.148641348\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 1056.504188776\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 63.219482183\n",
      "Epoch: 0001 cost= 1293.820358515\n",
      "STOPPED OVERFIT\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 55.078820705\n",
      "Epoch: 0001 cost= 1365.112502337\n",
      "STOPPED OVERFIT\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 35.295630693\n",
      "Epoch: 0001 cost= 1173.786051512\n",
      "STOPPED OVERFIT\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 50.632376432\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 1286.220030546\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 63.977319717\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 923.471908092\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 63.415194988\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 1925.670148611\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 64.384858847\n",
      "Epoch: 0001 cost= 1405.734410763\n",
      "STOPPED OVERFIT\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 52.101088762\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 950.586648703\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 241.662052870\n",
      "Epoch: 0001 cost= 1422.983196497\n",
      "STOPPED OVERFIT\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 74.364209652\n",
      "Epoch: 0001 cost= 1162.768792391\n",
      "STOPPED OVERFIT\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 51.803593397\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 937.275418758\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 63.878551483\n",
      "Epoch: 0001 cost= 1398.300847173\n",
      "STOPPED OVERFIT\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 75.077825069\n",
      "Epoch: 0001 cost= 1562.781561613\n",
      "STOPPED OVERFIT\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 49.653299093\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 1792.149374723\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 63.539009094\n",
      "Epoch: 0001 cost= 1398.235465527\n",
      "STOPPED OVERFIT\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 37.183797956\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 952.833792448\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 64.410020828\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 1274.397703171\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 62.366560698\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 1716.560683012\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 62.589920044\n",
      "Epoch: 0001 cost= 1181.869242191\n",
      "STOPPED OVERFIT\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 50.092033863\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 1488.809853315\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 96.514636755\n",
      "Epoch: 0001 cost= 1470.111584425\n",
      "STOPPED OVERFIT\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 36.471978426\n",
      "Epoch: 0001 cost= 1419.096791506\n",
      "STOPPED OVERFIT\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 32.649675846\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 1096.556561470\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 62.005381584\n",
      "Epoch: 0001 cost= 1082.553012371\n",
      "STOPPED OVERFIT\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 50.536731720\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 1269.090770483\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 62.436159611\n",
      "Epoch: 0001 cost= 1131.218850613\n",
      "STOPPED OVERFIT\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 46.880603075\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 1291.491787434\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 62.446233749\n",
      "Epoch: 0001 cost= 1055.012787104\n",
      "STOPPED OVERFIT\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 50.029641628\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 2735.654777765\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 63.488662720\n",
      "Epoch: 0001 cost= 1364.708093286\n",
      "STOPPED OVERFIT\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 55.044153094\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 1363.716374636\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 62.752167940\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 1040.231750011\n",
      "Epoch: 0001 cost= 321.822274685\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 1470.221117735\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 212.524214029\n",
      "STOPPED OVERFIT\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 2149.850048542\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 63.002091408\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 1108.268388510\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 83.522187233\n",
      "Epoch: 0001 cost= 1405.568808079\n",
      "STOPPED OVERFIT\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 36.403264523\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 2194.189058304\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 63.292116404\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 1069.123739243\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 63.396530390\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 1050.660199642\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 61.781189680\n",
      "Epoch: 0001 cost= 1558.359797716\n",
      "STOPPED OVERFIT\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 55.356663346\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 1073.194339752\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 63.579840183\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 2004.780941010\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 62.127760172\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 1191.722557783\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 63.423276424\n",
      "Epoch: 0001 cost= 1048.363401175\n",
      "STOPPED OVERFIT\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 50.710232258\n",
      "Epoch: 0001 cost= 1117.788092375\n",
      "STOPPED OVERFIT\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 52.500295639\n",
      "Epoch: 0001 cost= 1042.413454294\n",
      "STOPPED OVERFIT\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 46.281381369\n",
      "Epoch: 0001 cost= 1400.448939085\n",
      "STOPPED OVERFIT\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 35.300086498\n",
      "Epoch: 0001 cost= 1390.210048437\n",
      "STOPPED OVERFIT\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 69.352099299\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 1083.973036289\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 63.106489420\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 1066.397331953\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 270.169881582\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 1091.915199280\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 72.486382961\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 1464.235874653\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 61.085835695\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 1165.152892828\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 63.345845461\n",
      "Epoch: 0001 cost= 1448.831675291\n",
      "STOPPED OVERFIT\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 44.473892689\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 1090.980935097\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 62.728454828\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 1050.045458555\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 63.157920361\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 923.975401402\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 63.417997122\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 1120.978978872\n",
      "Epoch: 0001 cost= 320.909000158\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 1256.721629739\n",
      "STOPPED OVERFIT\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 37.837784767\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 896.649611235\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 62.781502485\n",
      "Epoch: 0001 cost= 1312.412507415\n",
      "STOPPED OVERFIT\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 43.378741741\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 1588.558032036\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 62.867079258\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 1767.820912123\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 63.510520935\n",
      "Epoch: 0001 cost= 1282.520243406\n",
      "STOPPED OVERFIT\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 49.318700075\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 1371.395009279\n",
      "Epoch: 0001 cost= 329.428046465\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 1390.772536278\n",
      "STOPPED OVERFIT\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 55.140363574\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 987.376025200\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 64.344998360\n",
      "New generation is being created.\n",
      "38565.0582764\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[31, 100, 128, 360]\n",
      "[145, 35, 168, 100, 160, 37, 110, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[31, 100, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[145, 35, 168, 100, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[31, 100, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[100, 128, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[145, 35, 168, 100, 360]\n",
      "[100, 128, 360]\n",
      "[100, 128, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[145, 35, 168, 100, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[145, 35, 168, 100, 360]\n",
      "[100, 360]\n",
      "[145, 35, 168, 100, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[31, 100, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[145, 35, 168, 100, 360]\n",
      "[100, 360]\n",
      "[31, 100, 360]\n",
      "[100, 128, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[31, 100, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[100, 160, 37, 110, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[100, 360]\n",
      "[100, 160, 37, 110, 360]\n",
      "Epoch: 0001 cost= 3896.100538254\n",
      "STOPPED OVERFIT\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 33.468525052\n",
      "Epoch: 0001 cost= 1486.077942848\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 187.889020324\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 1457.894551754\n",
      "STOPPED OVERFIT\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 38.495630145\n",
      "Epoch: 0001 cost= 1530.659444571\n",
      "STOPPED OVERFIT\n",
      "STOPPED OVERFIT\n",
      "Epoch: 0001 cost= 50.047795057\n",
      "Epoch: 0001 cost= 1496.906819820\n",
      "STOPPED OVERFIT\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    for i in range(x.population_size):\n",
    "        print(x.population[i].experiment.weights)\n",
    "        \n",
    "    x.evolve()\n",
    "    print(x.grade())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from genetic import evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
